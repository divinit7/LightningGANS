{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1130bd4e96544064847a09dda8df1b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9494ce5cb3164e208a8ab7b60376d765",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41f5370737c14164b8fc456fcf9e3f7d",
              "IPY_MODEL_465bab2a90bd4b49b57a4ad6cb80a707"
            ]
          }
        },
        "9494ce5cb3164e208a8ab7b60376d765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "41f5370737c14164b8fc456fcf9e3f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_567fd06291dc4cc7bacac36db4b46a65",
            "_dom_classes": [],
            "description": "Epoch 19: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 860,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 860,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d74097603ba948d29b991ec4f7fc95d9"
          }
        },
        "465bab2a90bd4b49b57a4ad6cb80a707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_081847a27c584575a7f7c2669936dd8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 860/860 [00:18&lt;00:00, 46.27it/s, loss=44.9, v_num=3, g_loss=90.90, d_loss=0.000]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb47100ded8445198927500a7f0a0198"
          }
        },
        "567fd06291dc4cc7bacac36db4b46a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d74097603ba948d29b991ec4f7fc95d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "081847a27c584575a7f7c2669936dd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb47100ded8445198927500a7f0a0198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEtdsIyd-5ee",
        "outputId": "4e8c9dd1-d06a-4371-cd9d-02fa6aa50bab"
      },
      "source": [
        "! pip install pytorch-lightning --q"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 849kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 15.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 34.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 22.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 32.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 36.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 58.3MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpZumb7yGaJM"
      },
      "source": [
        "import os\n",
        "from argparse import ArgumentParser\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import pytorch_lightning as pl"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTxkJ2JqJofK"
      },
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, data_dir: str = './', batch_size: int = 64, num_workers: int=8):\n",
        "    super().__init__()\n",
        "    self.data_dir = data_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.num_workers = num_workers\n",
        "\n",
        "    self.transform = transforms.Compose([\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    self.dims = (1, 28, 28)\n",
        "    self.num_classes = 10\n",
        "  \n",
        "  def prepare_data(self):\n",
        "    MNIST(self.data_dir, train = True, download = True)\n",
        "    MNIST(self.data_dir, train = False, download = True)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    if stage == 'fit' or stage is None:\n",
        "      mnist_full = MNIST(self.data_dir, train = True, transform = self.transform)\n",
        "      self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
        "\n",
        "    if stage == 'test' or stage is None:\n",
        "      self.mnist_test = MNIST(self.data_dir, train = False, transform = self.transform)\n",
        "    \n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers = self.num_workers)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_train, batch_size=self.batch_size, num_workers = self.num_workers)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers = self.num_workers)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUaad9elZi6_"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, latent_dim, img_shape):\n",
        "    super().__init__()\n",
        "    self.img_shape = img_shape\n",
        "  \n",
        "    def block(in_feat, out_feat, normalize=True):\n",
        "      layers = [nn.Linear(in_feat, out_feat)]\n",
        "      if normalize:\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace =True))\n",
        "      return layers\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "        *block(latent_dim, 128, normalize=False),\n",
        "        *block(128, 256),\n",
        "        *block(256, 512),\n",
        "        *block(512, 1024),\n",
        "        nn.Linear(1024, int(np.prod(img_shape))),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  \n",
        "  def forward(self, z):\n",
        "    img = self.model(z)\n",
        "    # print(img.shape)\n",
        "    img = img.view(img.shape[0], *self.img_shape)\n",
        "    # print(img.shape)\n",
        "    return img"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9B6OLOHaxOt"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(int(np.prod(img_shape)), 512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "  \n",
        "  def forward(self, img):\n",
        "    img_flat = img.view(img.size(0), -1)\n",
        "    validity = self.model(img_flat)\n",
        "\n",
        "    return validity"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFCgcWnfeeyq"
      },
      "source": [
        "class GAN(pl.LightningModule):\n",
        "  def __init__(self, channels, width, height, latent_dim: int=100, lr: float = 0.0002,\n",
        "               b1: float = 0.5, b2: float = 0.999, batch_size: int = 64, **kwargs):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "    data_shape = (channels, width, height)\n",
        "    self.generator = Generator(latent_dim=self.hparams.latent_dim, img_shape=data_shape)\n",
        "    self.discriminator = Discriminator(img_shape=data_shape)\n",
        "\n",
        "    self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
        "    self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
        "\n",
        "  def forward(self, z):\n",
        "    return self.generator(z)\n",
        "  \n",
        "  def adverserial_loss(self, y_hat, y):\n",
        "    return F.binary_cross_entropy(y_hat, y)\n",
        "\n",
        "  def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "    imgs, _ = batch\n",
        "\n",
        "    # sample noise\n",
        "    z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n",
        "    z = z.type_as(imgs)\n",
        "\n",
        "    # train generator\n",
        "    if optimizer_idx == 0:\n",
        "      # generate images\n",
        "      self.generated_imgs = self(z)\n",
        "\n",
        "      # log sampled images\n",
        "      sample_imgs = self.generated_imgs[:6]\n",
        "      grid = torchvision.utils.make_grid(sample_imgs)\n",
        "      self.logger.experiment.add_image('generated_images', grid, 0)\n",
        "\n",
        "      # ground truth result (i.e., all fake)\n",
        "      valid = torch.ones(imgs.size(0), 1)\n",
        "      valid = valid.type_as(imgs)\n",
        "\n",
        "      # adverserial loss is BCE\n",
        "      g_loss = self.adverserial_loss(self.discriminator(self(z)), valid)\n",
        "      tqdm_dict = {'g_loss': g_loss}\n",
        "      output = OrderedDict({\n",
        "          'loss': g_loss,\n",
        "          'progress_bar': tqdm_dict,\n",
        "          'log': tqdm_dict\n",
        "      })\n",
        "      return output\n",
        "    \n",
        "    if optimizer_idx == 1:\n",
        "\n",
        "      # train discriminator\n",
        "      valid = torch.ones(imgs.size(0), 1)\n",
        "      valid = valid.type_as(imgs)\n",
        "\n",
        "      fake = torch.zeros(imgs.size(0), 1)\n",
        "      fake = fake.type_as(imgs)\n",
        "\n",
        "      real_loss = self.adverserial_loss(self.discriminator(imgs), valid)\n",
        "\n",
        "      fake = torch.zeros(imgs.size(0), 1)\n",
        "      fake = fake.type_as(imgs)\n",
        "\n",
        "      fake_loss = self.adverserial_loss(self.discriminator(self(z).detach()), fake)\n",
        "\n",
        "    # discriminator loss is the average\n",
        "    d_loss = (real_loss + fake_loss) / 2\n",
        "    tqdm_dict = {'d_loss': d_loss}\n",
        "    output = OrderedDict({\n",
        "        'loss': d_loss,\n",
        "        'progress_bar': tqdm_dict,\n",
        "        'log': tqdm_dict\n",
        "    })\n",
        "    return output\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    lr = self.hparams.lr\n",
        "    b1 = self.hparams.b1\n",
        "    b2 = self.hparams.b2\n",
        "\n",
        "    opt_g = torch.optim.Adam(self.generator.parameters(), lr = lr, betas = (b1, b2))\n",
        "    opt_d = torch.optim.Adam(self.discriminator.parameters(), lr = lr, betas = (b1, b2))\n",
        "    return [opt_g, opt_d], []\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    z = self.validation_z.type_as(self.generator.model[0].weight)\n",
        "\n",
        "    #log sampled images\n",
        "    sample_imgs = self(z)\n",
        "    grid = torchvision.utils.make_grid(sample_imgs)\n",
        "    self.logger.experiment.add_image('generated_images', grid, self.current_epoch)\n",
        "\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "1130bd4e96544064847a09dda8df1b95",
            "9494ce5cb3164e208a8ab7b60376d765",
            "41f5370737c14164b8fc456fcf9e3f7d",
            "465bab2a90bd4b49b57a4ad6cb80a707",
            "567fd06291dc4cc7bacac36db4b46a65",
            "d74097603ba948d29b991ec4f7fc95d9",
            "081847a27c584575a7f7c2669936dd8b",
            "bb47100ded8445198927500a7f0a0198"
          ]
        },
        "id": "yboqayswlc9U",
        "outputId": "0fa98164-ec50-4400-ffee-a99333e43d05"
      },
      "source": [
        "dm = MNISTDataModule()\n",
        "model = GAN(*dm.size())\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=20, progress_bar_refresh_rate=20)\n",
        "trainer.fit(model, dm)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping validation loop\n",
            "  warnings.warn(*args, **kwargs)\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type          | Params | In sizes | Out sizes     \n",
            "----------------------------------------------------------------------------\n",
            "0 | generator     | Generator     | 1.5 M  | [2, 100] | [2, 1, 28, 28]\n",
            "1 | discriminator | Discriminator | 533 K  | ?        | ?             \n",
            "----------------------------------------------------------------------------\n",
            "2.0 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.0 M     Total params\n",
            "8.160     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1130bd4e96544064847a09dda8df1b95",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The {progress_bar:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
            "Please use self.log(...) inside the lightningModule instead.\n",
            "# log on a step or aggregate epoch metric to the logger and/or progress bar (inside LightningModule)\n",
            "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
            "Please use self.log(...) inside the lightningModule instead.\n",
            "# log on a step or aggregate epoch metric to the logger and/or progress bar (inside LightningModule)\n",
            "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "aR8N9CCTluEv",
        "outputId": "10cbec79-4b71-4570-87f4-20bac5e698cd"
      },
      "source": [
        "# Start tensorboard.\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 811), started 0:32:07 ago. (Use '!kill 811' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNha3v02tLjz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}